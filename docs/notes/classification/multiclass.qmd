---
jupyter: python3
execute:
  cache: true # re-render only when source changes
---

# Multiclass Classification


## Data Loading

In this chapter we will provide an example of multiclass classification, using the ["Palmer Penguins" dataset](https://github.com/mcnakhaee/palmerpenguins).

:::{.callout-tip title="Data Source"}
"Size measurements, clutch observations, and blood isotope ratios for 344 adult foraging Ad√©lie, Chinstrap, and Gentoo penguins observed on islands in the Palmer Archipelago near Palmer Station, Antarctica. Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica Long Term Ecological Research (LTER) Program."
:::


Our goal will be to predict the species of a penguin, given features such as their weight, size, and gender.

Loading the dataset:

```{python}
from palmerpenguins import load_penguins

df = load_penguins()
df.rename(columns={"sex": "gender"}, inplace=True)
df["species"] = df["species"].str.upper()
df["island"] = df["island"].str.upper()
df["gender"] = df["gender"].str.upper()
df.drop(columns=["year"], inplace=True)
df.head()
```

As you can see, the target variable is categorical, which makes this a multiclass classification task:

```{python}
df["species"].value_counts()
```


### Data Cleaning

### Null Values

Checking for null values:

```{python}
df.isnull().sum()
```

Looks like there are some null values. Since the number of nulls is small, we can feel free to drop those rows from our analysis.

Dropping nulls:

```{python}
print(len(df))

df.dropna(inplace=True)

print(len(df))
```

```{python}
df.isnull().sum()
```

## Data Exploration

Investigating features, such as the `island`:

```{python}
df["island"].value_counts()
```

What other variables are you interested in exploring?

### Relationships

Let's examine the weight of a penguin, by island, to see if we can notice any patterns in the data:

```{python}
import plotly.express as px

px.scatter(df, x="body_mass_g", y="island", color="species",
  title="Body Mass by Penguin Species", height=300
)
```

It looks like island and weight might be suitable features, as they help differentiate between the various species. Specifically we can make the following observations:

  + Only one species of penguin lives on "Torgersen" island.
  + Two species of penguin live on "Biscoe" island, but these species are separable by their weight.
  + Two species of penguin live on "Dream" island, but the data aren't separable by weight, so we might need additional features.

We are starting to develop an intuition that penguins on the "Dream" island might be the hardest to classify.

### Pair Plots

Examining the relationships between each pair of variables:

```{python}
from seaborn import pairplot

pairplot(df, hue="species", height=1.5) # height in inches
```

What relationships do you notice between specific pairs of variables? Which features could potentially help us separate or differentiate members of the different classes?


### Correlation

Examining the correlation between each pair of variables, as a more formal measure of their relationships:

```{python}
#| code-fold: true

from pandas import DataFrame
import plotly.express as px

def plot_correlation_matrix(df: DataFrame, method="pearson", height=450, showscale=True):
    """Params: method (str): "spearman" or "pearson".
    """

    cor_mat = df.corr(method=method, numeric_only=True)

    title= f"{method.title()} Correlation"

    fig = px.imshow(cor_mat,
                    height=height, # title=title,
                    text_auto= ".2f", # round to two decimal places
                    color_continuous_scale="Blues",
                    color_continuous_midpoint=0,
                    labels={"x": "Variable", "y": "Variable"},
    )
    # center title (h/t: https://stackoverflow.com/questions/64571789/)
    fig.update_layout(title={'text': title, 'x':0.485, 'xanchor': 'center'})
    fig.update_coloraxes(showscale=showscale)
    fig.show()

```


```{python}
plot_correlation_matrix(df, method="spearman", height=450)
```


What lessons are we learning about correlation of certain variables?


## X/Y Split

Choosing the species as our target, and all the other variables as our features:

```{python}
target = "species"

x = df.drop(columns=[target])
y = df[target]

print("X:", x.shape)
print("Y:", y.shape)
```

## Data Encoding

Since some features are categorical, we must encode them. Here we are using a one-hot-encoding approach:

```{python}
from pandas import get_dummies as one_hot_encode

# since encoding transforms and removes the original columns,
# only try to encode if we haven't already done so:
if "island" in x.columns:
    x = one_hot_encode(x, columns=["island", "gender"], dtype=int)

print("X:", x.shape)
x.head()
```


Now that we have encoded the categorical features we can examine their correlation as well:

```{python}
plot_correlation_matrix(x, method="spearman", height=550, showscale=False)
```

What lessons are we learning about the correlation of these additional variables?


## Feature Scaling

Since we have multiple features, it may be helpful to scale them, to express their values using similar scales, and prevent some features from artificially overpowering the model. Here we are using a standard scaling approach:

```{python}
x_scaled = (x - x.mean(axis=0)) / x.std(axis=0)
x_scaled.head()
```

Verifying mean centering and unit variance:

```{python}
x_scaled.describe().T[["mean", "std"]]
```

## Train/Test Split

Splitting the dataset into training and test sets:

```{python}
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=99)

print("TRAIN:", x_train.shape, y_train.shape)
print("TEST:", x_test.shape, y_test.shape)
```


## Model Selection

Using a `LogisticRegression` model, which is the standard basic classification model we generally use for benchmarking purposes:

```{python}
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(random_state=99)
```

FYI - this model has some parameters we can tune later, if desired (see the [`LogisticRegression` docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)):

```{python}
model.get_params()
```

## Model Training

Training the model on the training data:

```{python}
model.fit(x_train, y_train)
```

Getting artifacts of the training process, specifically focusing on the coefficients:

```{python}
model.coef_.shape
```

Unlike binary classification in which there are a single set of coefficients, in multiclass classification there are a different set of coefficients for each of the classes present in our target variable. In other words, each feature may contribute differently to predicting members of the different species.

Wrapping the coefficients in a `DataFrame`, using corresponding column and index labels, allows us sort and compare them:


```{python}
model.classes_
```

```{python}
model.feature_names_in_
```

```{python}
from pandas import Series, DataFrame

coefs = DataFrame(model.coef_, columns=x_scaled.columns, index=model.classes_).T
coefs
```

Examining the coefficients for each species:

```{python}
coefs["ADELIE"].sort_values(ascending=False)
```


```{python}
coefs["CHINSTRAP"].sort_values(ascending=False)
```



```{python}
coefs["GENTOO"].sort_values(ascending=False)
```

How can we interpret these coefficients?


## Model Evaluation

Now it's time to evaluate the model.


Predicting values for the unseen test data:

```{python}
y_pred = model.predict(x_test)
```

### Classification Metrics

We are using our standard classification metrics, focusing on the classification report:

```{python}
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))
```

How can we interpret these results? How did the model do overall? Are there any species that are easier or harder to classify than others?

### Confusion Matrix

Using a confusion matrix to examine false positives and false negatives for each species:


```{python}
from sklearn.metrics import confusion_matrix

print(confusion_matrix(y_test, y_pred, labels=model.classes_))
```

Plotting the confusion matrix, for easier interpretation:


```{python}
#| code-fold: true

from sklearn.metrics import confusion_matrix
import plotly.express as px

def plot_confusion_matrix(y_true, y_pred, height=450, showscale=False, title=None, subtitle=None):
    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html
    # Confusion matrix whose i-th row and j-th column
    # ... indicates the number of samples with
    # ... true label being i-th class (ROW)
    # ... and predicted label being j-th class (COLUMN)
    cm = confusion_matrix(y_true, y_pred)

    class_names = sorted(y_test.unique().tolist())

    cm = confusion_matrix(y_test, y_pred, labels=class_names)

    title = title or "Confusion Matrix"
    if subtitle:
        title += f"<br><sup>{subtitle}</sup>"

    fig = px.imshow(cm, x=class_names, y=class_names, height=height,
                    labels={"x": "Predicted", "y": "Actual"},
                    color_continuous_scale="Blues", text_auto=True,
    )
    fig.update_layout(title={'text': title, 'x':0.485, 'xanchor': 'center'})
    fig.update_coloraxes(showscale=showscale)

    fig.show()

```


```{python}

title = "Penguin Species Classifier - Confusion Matrix"
plot_confusion_matrix(y_test, y_pred, title=title, height=400)
```

### ROC-AUC

To calculate the ROC for multiclass classification, we need to use the underlying **predicted probabilities** ("logits") for each class:

```{python}
y_pred_proba = model.predict_proba(x_test)
print(y_pred_proba.shape)
```

Under the hood, the model assigns a different probability for each class. For its final prediction, the model chooses the class that has the highest likelihood (i.e. the "argmax") for each row:

```{python}
logits_df = DataFrame(y_pred_proba, columns=model.classes_)
logits_df["FINAL_PREDICTION"] = y_pred
logits_df.head()
```


Calculating the ROC score, using the predicted probabilities:


```{python}
from sklearn.metrics import roc_auc_score

def compute_roc_auc_score(y_test, y_pred_proba, is_multiclass=True):
    """NOTE: roc_auc_score uses average='macro' by default"""

    if is_multiclass:
        return roc_auc_score(y_true=y_test, y_score=y_pred_proba, multi_class="ovr")
    else:
        y_pred_proba_pos = y_pred_proba[:,1] # positive class (for binary classification)
        return roc_auc_score(y_true=y_test, y_score=y_pred_proba_pos)



compute_roc_auc_score(y_test, y_pred_proba)
```


Feel free to apply these same techniques any time you are performing classification on a target that has multiple classes.
